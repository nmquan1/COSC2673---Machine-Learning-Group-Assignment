{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6W5COkX-JbB"
      },
      "source": [
        "# **CLASSFICATION BY SHAPE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIsU-0E9-kax"
      },
      "source": [
        "This model is built to classify the shape of Road Traffic sign images from given dataset following the process learnt in class and lab sessions, which consists of these main sub-secitons:\n",
        "\n",
        "\n",
        "1. Importing necessary libraries and functions\n",
        "2. Declaring datapath: this project involves two students, so we declared two different directories for each.\n",
        "3. Reading data\n",
        "4. Checking for data's size, number of images in each categories, duplicates, etc\n",
        "5. Process data\n",
        "6. Divide the data to independent train, validation and test set.\n",
        "7. Building the baseline model\n",
        "8. Enhance the performance of the model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8Ca_6S795ne"
      },
      "source": [
        "**DECLARING DIRECTORIES AND READING DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7zzHt_xD-r2",
        "outputId": "0f8fa31c-b02c-4a66-a30d-e43a4371dfe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Mounted at /content/drive\n",
            "Pandas version: 2.0.3\n",
            "TensorFlow version: 2.15.0\n",
            "Pillow version: 9.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tabulate\n",
        "\n",
        "#import basic libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import os, sys\n",
        "import glob\n",
        "import pathlib\n",
        "import tempfile\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from tabulate import tabulate\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Dropout, Rescaling, Conv2D, MaxPooling2D, Activation\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "\n",
        "# Mount Google Drive (if not mounted, in which btw, definitely was not)\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount = True)\n",
        "\n",
        "os.environ['env_for_s3977994'] = '/content/drive/MyDrive/MachineLearning_ASM2/pyTools/'\n",
        "os.environ['env_for_s3979391'] = '/content/drive/My Drive/models/'\n",
        "env = os.getenv('env_for_s3977994')\n",
        "sys.path.append(env)\n",
        "\n",
        "# Custom functions\n",
        "from utils import *\n",
        "\n",
        "# Print out versions for important tools\n",
        "print(\"Pandas version:\", pd.__version__)\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Pillow version:\", PIL.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yxDn9qiciv-d"
      },
      "outputs": [],
      "source": [
        "gpu_conf = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpu_conf:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7648hfV7BcWd"
      },
      "source": [
        "**ERROR HANDLING FOR READING DATA DIRECTORIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W3pp1KR4C8MQ"
      },
      "outputs": [],
      "source": [
        "# Define the path to your Google Drive folder containing the images\n",
        "google_drive_folder = \"../content/drive/MyDrive/MachineLearning_ASM2/trafficsigns_dataset\"\n",
        "\n",
        "# Create a pathlib.Path object pointing to your Google Drive folder\n",
        "data_dir = pathlib.Path(google_drive_folder)\n",
        "\n",
        "# Ensure the directory exists\n",
        "if not data_dir.exists():\n",
        "    raise ValueError(f\"Directory {data_dir} does not exist. Please check the path.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UROep6bCBM8s"
      },
      "source": [
        "**TOTAL NUMBER OF IMAGES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbtTDYhOHZb6",
        "outputId": "29ba95e4-7355-4b8a-bd71-de8cff236d22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3699\n"
          ]
        }
      ],
      "source": [
        "image_count = len(list(data_dir.glob('*/**/*.png')))\n",
        "print(image_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-G-nhgQBrnB"
      },
      "source": [
        "**DIRECTORY TREE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drFRFAUjvtOP",
        "outputId": "7468f41a-e646-479e-ef5d-c8f77c0d9322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "├───trafficsigns_dataset/\n",
            "    ├───square/\n",
            "        ├───continue/\n",
            "        ├───parking/\n",
            "        ├───crossing/\n",
            "        ├───laneend/\n",
            "    ├───hex/\n",
            "        ├───stop/\n",
            "    ├───triangle/\n",
            "        ├───warning/\n",
            "        ├───giveway/\n",
            "    ├───round/\n",
            "        ├───speed/\n",
            "        ├───limitedtraffic/\n",
            "        ├───noparking/\n",
            "        ├───bicycle/\n",
            "        ├───roundabout/\n",
            "        ├───noentry/\n",
            "        ├───trafficdirective/\n",
            "        ├───traveldirection/\n",
            "    ├───diamond/\n",
            "        ├───rightofway/\n"
          ]
        }
      ],
      "source": [
        "print_directory_tree(google_drive_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4LgYwvhB1FV"
      },
      "source": [
        "**PRINT NUMBER OF IMAGES FOR EACH CATEGORY**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAidHD7tU91S",
        "outputId": "90ac8d82-9b02-4b7c-9c61-50aa6b35188a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------------------+\n",
            "|    Directory     | Number of Images |\n",
            "+------------------+------------------+\n",
            "|     continue     |       199        |\n",
            "|     parking      |       276        |\n",
            "|     crossing     |        95        |\n",
            "|     laneend      |       118        |\n",
            "|       stop       |        43        |\n",
            "|     warning      |       695        |\n",
            "|     giveway      |       231        |\n",
            "|      speed       |       316        |\n",
            "|  limitedtraffic  |       125        |\n",
            "|    noparking     |       242        |\n",
            "|     bicycle      |       285        |\n",
            "|    roundabout    |        98        |\n",
            "|     noentry      |       375        |\n",
            "| trafficdirective |       195        |\n",
            "| traveldirection  |       124        |\n",
            "|    rightofway    |       282        |\n",
            "+------------------+------------------+\n"
          ]
        }
      ],
      "source": [
        "print_summary(data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1hIKuWSW186"
      },
      "source": [
        "**DUPLICATE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "dL2XjDUcJi8B",
        "outputId": "38777ffd-70e2-4732-8855-8f2c3ed0088b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-90d7ad2c8fa9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/drive/MyDrive/MachineLearning_ASM2/pyTools/utils.py\u001b[0m in \u001b[0;36mprint_duplicates\u001b[0;34m(dataset_dir)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;31m# Access to the returned value of find_duplicates(dataset_dir) function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mduplicates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_duplicates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of duplicates found: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_duplicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Duplicates: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/MachineLearning_ASM2/pyTools/utils.py\u001b[0m in \u001b[0;36mfind_duplicates\u001b[0;34m(dataset_dir)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Get the file's path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mfile_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Compute the current image's hash value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;31m# If the current image's hash value is found in the dictionary of hash values that have been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/MachineLearning_ASM2/pyTools/utils.py\u001b[0m in \u001b[0;36mcompute_hash\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Compute the hash value of an image file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mimage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;31m# Return the image's hash value (in hex)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmd5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print_duplicates(data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUOKql3JypT-"
      },
      "source": [
        "**LABEL DATA**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiO-LebHVCiO",
        "outputId": "595f4534-cbca-4747-a24a-6444bf09823a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3699 files belonging to 5 classes.\n",
            "Classes: ['diamond', 'hex', 'round', 'square', 'triangle']\n",
            "Total number of images in square class:  688\n",
            "Total number of images in hex class:  43\n",
            "Total number of images in triangle class:  926\n",
            "Total number of images in round class:  1760\n",
            "Total number of images in diamond class:  282\n"
          ]
        }
      ],
      "source": [
        "# Use the functions\n",
        "data = labeled_by_shape(data_dir)\n",
        "print(\"Classes:\", data.class_names)\n",
        "image_count = len(list(data_dir.glob('square/**/*.png')))\n",
        "print(\"Total number of images in square class: \", image_count)\n",
        "image_count = len(list(data_dir.glob('hex/**/*.png')))\n",
        "print(\"Total number of images in hex class: \", image_count)\n",
        "image_count = len(list(data_dir.glob('triangle/**/*.png')))\n",
        "print(\"Total number of images in triangle class: \", image_count)\n",
        "image_count = len(list(data_dir.glob('round/**/*.png')))\n",
        "print(\"Total number of images in round class: \", image_count)\n",
        "image_count = len(list(data_dir.glob('diamond/**/*.png')))\n",
        "print(\"Total number of images in diamond class: \", image_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGT2PNavy0Vt"
      },
      "source": [
        "**CALCULATE CLASS WEIGHT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp4P6vzTJ--q",
        "outputId": "65dcd5bd-39f0-4563-a0c4-61cdd1033a49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'square': 1.0752906976744185, 'hex': 17.204651162790697, 'triangle': 0.7989200863930885, 'round': 0.4203409090909091, 'diamond': 2.623404255319149}\n",
            "{0: 1.0752906976744185, 1: 17.204651162790697, 2: 0.7989200863930885, 3: 0.4203409090909091, 4: 2.623404255319149}\n"
          ]
        }
      ],
      "source": [
        "class_counts = {\n",
        "    'square': len(list(data_dir.glob('square/**/*.png'))),\n",
        "    'hex': len(list(data_dir.glob('hex/**/*.png'))),\n",
        "    'triangle': len(list(data_dir.glob('triangle/**/*.png'))),\n",
        "    'round': len(list(data_dir.glob('round/**/*.png'))),\n",
        "    'diamond': len(list(data_dir.glob('diamond/**/*.png')))\n",
        "}\n",
        "\n",
        "# Get the list of class names in the same order as the indices\n",
        "class_names = list(class_counts.keys())\n",
        "\n",
        "# Create a label encoder to convert class names to indices\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(class_names)\n",
        "\n",
        "# Convert class names to class indices\n",
        "class_indices = {class_name: label_encoder.transform([class_name])[0] for class_name in class_names}\n",
        "\n",
        "total_samples = sum(class_counts.values())\n",
        "class_weights = {cls: total_samples / (len(class_counts) * count) for cls, count in class_counts.items()}\n",
        "print(class_weights)\n",
        "\n",
        "# Assign unique integer labels to each class\n",
        "label_encoder = {class_name: i for i, class_name in enumerate(class_weights.keys())}\n",
        "\n",
        "# Encode class weights with integer labels\n",
        "encoded_class_weights = {label_encoder[class_name]: weight for class_name, weight in class_weights.items()}\n",
        "print(encoded_class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-g6BJS3PfqZt"
      },
      "outputs": [],
      "source": [
        "# # Normalize class weights\n",
        "# max_weight = max(class_weights.values())\n",
        "# for class_name in class_weights:\n",
        "#     class_weights[class_name] /= max_weight\n",
        "\n",
        "# # Print the normalized class weights\n",
        "# print(class_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23n4_gFYW_us"
      },
      "source": [
        "**BASELINE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "foYJGQsPXDPw"
      },
      "outputs": [],
      "source": [
        "train_size = int(len(data)*.7)\n",
        "val_size = int(len(data)*.2)\n",
        "test_size = int(len(data)*.1)\n",
        "\n",
        "train = data.take(train_size)\n",
        "val = data.skip(train_size).take(val_size)\n",
        "test = data.skip(train_size+val_size).take(test_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II44FJttzX6G"
      },
      "source": [
        "Starting with a multilayer perceptron model (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "smY1IDpRp-gT"
      },
      "outputs": [],
      "source": [
        "baseline_model = Sequential([\n",
        "    Rescaling(1./255, input_shape=(256, 256, 1)),\n",
        "    Flatten(),\n",
        "    BatchNormalization(),  # Batch normalization\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    BatchNormalization(),  # Batch normalization\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(5, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnBa9aTKXdVM",
        "outputId": "c1278071-34bd-4222-8c6d-a6f3d0c3b2b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/81 [===========>..................] - ETA: 2:13 - loss: 1.9237 - sparse_categorical_accuracy: 0.4555"
          ]
        }
      ],
      "source": [
        "baseline_model.compile (\n",
        "    optimizer='SGD',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs')\n",
        "\n",
        "baseline_model.fit(\n",
        "    train,\n",
        "    epochs=20,\n",
        "    batch_size = 5,\n",
        "    validation_data=val,\n",
        "    callbacks=[tensorboard_callback],  # Any additional callbacks you might need\n",
        "    class_weight=encoded_class_weights\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw2SRHSK6CC2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation\n",
        "\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Conv2D(filters = 16, kernel_size=(10,10), padding = 'Same', activation = 'relu', input_shape = (256, 256, 1)))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model2.add(Conv2D(filters = 32, kernel_size=(10,10), padding = 'Same', activation = 'relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "model2.add(Conv2D(filters = 32, kernel_size =(10,10), padding = 'Same', activation = 'relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "# model2.add(Conv2D(filters = 32, kernel_size =(3,3), padding = 'Same', activation = 'relu'))\n",
        "# model2.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(32))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dense(5, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMo3gWT49jdS"
      },
      "outputs": [],
      "source": [
        "model2.compile (\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy'],\n",
        ")\n",
        "\n",
        "model2.fit(\n",
        "    train,\n",
        "    epochs=20,\n",
        "    batch_size = 32,\n",
        "    validation_data=val,\n",
        "    # class_weight=class_weights\n",
        ")\n",
        "\n",
        "# print(data)\n",
        "# print(data.class_names)\n",
        "# print(train)\n",
        "# print(train.class_names)\n",
        "# print(test)\n",
        "# print(test.class_names)\n",
        "# print(val)\n",
        "# print(val.class_names)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLYr7CjoJWBn"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}